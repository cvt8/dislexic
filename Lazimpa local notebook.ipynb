{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54e6a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir -p dir_save/{accuracy,messages,sender,receiver}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb12b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0679cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Namespace(n_features=100, batches_per_epoch=100, dim_dataset=10240, force_eos=0, sender_hidden=250, receiver_hidden=600, receiver_num_layers=1, sender_num_layers=1, receiver_num_heads=8, sender_num_heads=8, sender_embedding=10, receiver_embedding=100, causal_sender=False, causal_receiver=False, sender_generate_style='in-place', sender_cell='lstm', receiver_cell='lstm', sender_entropy_coeff=2.0, receiver_entropy_coeff=0.1, probs='powerlaw', length_cost=0.0, name='model', early_stopping_thr=0.99, dir_save='dir_save', unigram_pen=0.0, impatient=True, print_message=True, reg=True, random_seed=7, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=200, load_from_checkpoint=None, no_cuda=False, batch_size=512, optimizer='adam', lr=0.001, vocab_size=40, max_len=30, tensorboard=False, tensorboard_dir='runs/', cuda=True, device='cuda')\n",
      "the probs are:  [0.1927756  0.0963878  0.06425854 0.0481939  0.03855512 0.03212927\n",
      " 0.02753937 0.02409695 0.02141951 0.01927756 0.01752505 0.01606463\n",
      " 0.01482889 0.01376969 0.01285171 0.01204848 0.01133974 0.01070976\n",
      " 0.01014608 0.00963878 0.00917979 0.00876253 0.00838155 0.00803232\n",
      " 0.00771102 0.00741445 0.00713984 0.00688484 0.00664743 0.00642585\n",
      " 0.00621857 0.00602424 0.00584168 0.00566987 0.00550787 0.00535488\n",
      " 0.00521015 0.00507304 0.00494296 0.00481939 0.00470184 0.0045899\n",
      " 0.00448315 0.00438126 0.0042839  0.00419077 0.00410161 0.00401616\n",
      " 0.0039342  0.00385551 0.00377991 0.00370722 0.00363728 0.00356992\n",
      " 0.00350501 0.00344242 0.00338203 0.00332372 0.00326738 0.00321293\n",
      " 0.00316026 0.00310928 0.00305993 0.00301212 0.00296578 0.00292084\n",
      " 0.00287725 0.00283494 0.00279385 0.00275394 0.00271515 0.00267744\n",
      " 0.00264076 0.00260508 0.00257034 0.00253652 0.00250358 0.00247148\n",
      " 0.0024402  0.0024097  0.00237995 0.00235092 0.0023226  0.00229495\n",
      " 0.00226795 0.00224158 0.00221581 0.00219063 0.00216602 0.00214195\n",
      " 0.00211841 0.00209539 0.00207286 0.0020508  0.00202922 0.00200808\n",
      " 0.00198738 0.0019671  0.00194723 0.00192776]\n",
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "'lengths' argument should be a 1D CPU int64 tensor, but got 1D cuda:0 Long tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9934/2464384753.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     main(['--dir_save=dir_save', '--vocab_size=40', '--max_len=30', '--impatient=False', '--reg=False', '--n_features=100', '--print_message=False', '--random_seed=7',\n\u001b[0m\u001b[1;32m    399\u001b[0m           \u001b[0;34m'--probs=powerlaw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--n_epoch=200'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--batch_size=512'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--length_cost=0.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--sender_cell=lstm'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'--receiver_cell=lstm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--sender_hidden=250'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m           \u001b[0;34m'--receiver_hidden=600'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--receiver_embedding=100'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--sender_embedding=10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--batches_per_epoch=100'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--lr=0.001'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--sender_entropy_coeff=2.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9934/2464384753.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    367\u001b[0m           \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{opts.name}_vocab{opts.vocab_size}_rs{opts.random_seed}_lr{opts.lr}_shid{opts.sender_hidden}_rhid{opts.receiver_hidden}_sentr{opts.sender_entropy_coeff}_reg{opts.length_cost}_max_len{opts.max_len}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nextcloud/ENS/Cognitive sciences/MVA langage proc/egg/core/trainers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nextcloud/ENS/Cognitive sciences/MVA langage proc/egg/core/trainers.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0moptimized_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mmean_rest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_rest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0moptimized_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nextcloud/ENS/Cognitive sciences/MVA langage proc/egg/core/reinforce_wrappers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sender_input, labels, receiver_input)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m# If impatient 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mreceiver_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreceiver_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \"\"\" NOISE VERSION\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nextcloud/ENS/Cognitive sciences/MVA langage proc/egg/core/reinforce_wrappers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, message, input, lengths)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nextcloud/ENS/Cognitive sciences/MVA langage proc/egg/core/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, message, lengths)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         packed = nn.utils.rnn.pack_padded_sequence(\n\u001b[0m\u001b[1;32m    115\u001b[0m             emb, lengths, batch_first=True, enforce_sorted=False)\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 'lengths' argument should be a 1D CPU int64 tensor, but got 1D cuda:0 Long tensor"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import egg.core as core\n",
    "from egg.core import EarlyStopperAccuracy\n",
    "from egg.zoo.channel.features import OneHotLoader, UniformLoader\n",
    "from egg.zoo.channel.archs import Sender, Receiver\n",
    "from egg.core.reinforce_wrappers import RnnReceiverImpatient\n",
    "from egg.core.reinforce_wrappers import SenderImpatientReceiverRnnReinforce\n",
    "from egg.core.util import dump_sender_receiver_impatient\n",
    "\n",
    "def get_params(params):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_features', type=int, default=10,\n",
    "                        help='Dimensionality of the \"concept\" space (default: 10)')\n",
    "    parser.add_argument('--batches_per_epoch', type=int, default=1000,\n",
    "                        help='Number of batches per epoch (default: 1000)')\n",
    "    parser.add_argument('--dim_dataset', type=int, default=10240,\n",
    "                        help='Dim of constructing the data (default: 10240)')\n",
    "    parser.add_argument('--force_eos', type=int, default=0,\n",
    "                        help='Force EOS at the end of the messages (default: 0)')\n",
    "\n",
    "    parser.add_argument('--sender_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Receiver (default: 10)')\n",
    "    parser.add_argument('--receiver_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--sender_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--receiver_num_heads', type=int, default=8,\n",
    "                        help='Number of attention heads for Transformer Receiver (default: 8)')\n",
    "    parser.add_argument('--sender_num_heads', type=int, default=8,\n",
    "                        help='Number of self-attention heads for Transformer Sender (default: 8)')\n",
    "    parser.add_argument('--sender_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Receiver (default: 10)')\n",
    "\n",
    "    parser.add_argument('--causal_sender', default=False, action='store_true')\n",
    "    parser.add_argument('--causal_receiver', default=False, action='store_true')\n",
    "\n",
    "    parser.add_argument('--sender_generate_style', type=str, default='in-place', choices=['standard', 'in-place'],\n",
    "                        help='How the next symbol is generated within the TransformerDecoder (default: in-place)')\n",
    "\n",
    "    parser.add_argument('--sender_cell', type=str, default='rnn',\n",
    "                        help='Type of the cell used for Sender {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "    parser.add_argument('--receiver_cell', type=str, default='rnn',\n",
    "                        help='Type of the model used for Receiver {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "\n",
    "    parser.add_argument('--sender_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Sender (default: 1e-1)')\n",
    "    parser.add_argument('--receiver_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Receiver (default: 1e-1)')\n",
    "\n",
    "    parser.add_argument('--probs', type=str, default='uniform',\n",
    "                        help=\"Prior distribution over the concepts (default: uniform)\")\n",
    "    parser.add_argument('--length_cost', type=float, default=0.0,\n",
    "                        help=\"Penalty for the message length, each symbol would before <EOS> would be \"\n",
    "                             \"penalized by this cost (default: 0.0)\")\n",
    "    parser.add_argument('--name', type=str, default='model',\n",
    "                        help=\"Name for your checkpoint (default: model)\")\n",
    "    parser.add_argument('--early_stopping_thr', type=float, default=0.9999,\n",
    "                        help=\"Early stopping threshold on accuracy (default: 0.9999)\")\n",
    "\n",
    "    # AJOUT\n",
    "    parser.add_argument('--dir_save', type=str, default=\"expe_1\",\n",
    "                        help=\"Directory in which we will save the information\")\n",
    "    parser.add_argument('--unigram_pen', type=float, default=0.0,\n",
    "                        help=\"Add a penalty for redundancy\")\n",
    "    parser.add_argument('--impatient', type=bool, default=False,\n",
    "                        help=\"Impatient listener\")\n",
    "    parser.add_argument('--print_message', type=bool, default=False,\n",
    "                        help='Print message ?')\n",
    "    parser.add_argument('--reg', type=bool, default=False,\n",
    "                        help='Add regularization ?')\n",
    "\n",
    "    args = core.init(parser, params)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def loss(sender_input, _message, _receiver_input, receiver_output, _labels):\n",
    "    acc = (receiver_output.argmax(dim=1) == sender_input.argmax(dim=1)).detach().float()\n",
    "    loss = F.cross_entropy(receiver_output, sender_input.argmax(dim=1), reduction=\"none\")\n",
    "    return loss, {'acc': acc}\n",
    "\n",
    "def loss_impatient(sender_input, _message, message_length, _receiver_input, receiver_output, _labels):\n",
    "\n",
    "    \"\"\"\n",
    "    Compute the loss function for the Impatient Listener.\n",
    "    It is equal to the average cross entropy of all the intermediate predictions\n",
    "\n",
    "    Params:\n",
    "    - sender_input: ground truth 1-hot vector | size=(batch_size,n_features)\n",
    "    - receiver_output: receiver predictions | size=(batch_size,max_len,n_features)\n",
    "    - message_lengh: message length | size=(batch_size)\n",
    "\n",
    "    Returns:\n",
    "    - loss: |  size= ????\n",
    "    - {acc:acc}: mean accuracy | size=(batch_size)\n",
    "    - crible_acc: accuracy by position | size=(batch_size,max_len)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. len_mask selects only the symbols before EOS-token\n",
    "    to_onehot=torch.eye(_message.size(1)).to(\"cuda\")\n",
    "    to_onehot=torch.cat((to_onehot,torch.zeros((1,_message.size(1))).to(\"cuda\")),0)\n",
    "    len_mask=[]\n",
    "    for i in range(message_length.size(0)):\n",
    "      len_mask.append(to_onehot[message_length[i]])\n",
    "    len_mask=torch.stack(len_mask,dim=0)\n",
    "\n",
    "    len_mask=torch.cumsum(len_mask,dim=1)\n",
    "    len_mask=torch.ones(len_mask.size()).to(\"cuda\").add_(-len_mask)\n",
    "\n",
    "    # 2. coef applies weights on each position. By default it is equal\n",
    "    coef=(1/message_length.to(float)).repeat(_message.size(1),1).transpose(1,0) # useless ?\n",
    "    coef2=coef # useless ?\n",
    "    len_mask.mul_((coef2)) # useless ?\n",
    "    len_mask.mul_((1/len_mask.sum(1)).repeat((_message.size(1),1)).transpose(1,0))\n",
    "\n",
    "    # Test: change positional wieghts\n",
    "    #coef2=coef*torch.arange(_message.size(1),0,-1).repeat(_message.size(0),1).to(\"cuda\")\n",
    "\n",
    "\n",
    "    # 3. crible_acc gathers accuracy for each input/position, crible_loss gathers losses for each input/position\n",
    "    crible_acc=torch.zeros(size=_message.size()).to(\"cuda\")\n",
    "    crible_loss=torch.zeros(size=_message.size()).to(\"cuda\")\n",
    "\n",
    "    for i in range(receiver_output.size(1)):\n",
    "      crible_acc[:,i].add_((receiver_output[:,i,:].argmax(dim=1) == sender_input.argmax(dim=1)).detach().float())\n",
    "      crible_loss[:,i].add_(F.cross_entropy(receiver_output[:,i,:], sender_input.argmax(dim=1), reduction=\"none\"))\n",
    "\n",
    "    # 4. Apply mask to remove the positions after EOS-token\n",
    "    acc=crible_acc*len_mask\n",
    "    loss=crible_loss*len_mask\n",
    "\n",
    "    acc = acc.sum(1)\n",
    "    loss= loss.sum(1)\n",
    "\n",
    "    return loss, {'acc': acc}, crible_acc\n",
    "\n",
    "#def loss_impatient2(sender_input, _message, message_length, _receiver_input, receiver_output, _labels):\n",
    "\n",
    "#    to_onehot=torch.eye(_message.size(1)).to(\"cuda\")\n",
    "#    to_onehot=torch.cat((to_onehot,torch.zeros((1,_message.size(1))).to(\"cuda\")),0)\n",
    "#    len_mask=[]\n",
    "#    len_mask2=[]\n",
    "#    for i in range(message_length.size(0)):\n",
    "#      len_mask.append(to_onehot[message_length[i]])\n",
    "#      len_mask2.append(to_onehot[message_length[i]-1])\n",
    "#    len_mask=torch.stack(len_mask,dim=0)\n",
    "#    len_mask2=torch.stack(len_mask2,dim=0)\n",
    "\n",
    "#    coef=(1/message_length.to(float)).repeat(_message.size(1),1).transpose(1,0)\n",
    "#    coef2=coef*torch.arange(_message.size(1),0,-1).repeat(_message.size(0),1).to(\"cuda\")\n",
    "\n",
    "#    len_mask=torch.cumsum(len_mask,dim=1)\n",
    "#    len_mask=torch.ones(len_mask.size()).to(\"cuda\").add_(-len_mask)\n",
    "\n",
    "#    len_mask.mul_((coef2))\n",
    "#    len_mask.mul_((1/len_mask.sum(1)).repeat((_message.size(1),1)).transpose(1,0))\n",
    "\n",
    "#    crible_acc=torch.zeros(size=_message.size()).to(\"cuda\")\n",
    "#    crible_loss=torch.zeros(size=_message.size()).to(\"cuda\")\n",
    "\n",
    "#    for i in range(receiver_output.size(1)):\n",
    "#      crible_acc[:,i].add_((receiver_output[:,i,:].argmax(dim=1) == sender_input.argmax(dim=1)).detach().float())\n",
    "#      crible_loss[:,i].add_(F.cross_entropy(receiver_output[:,i,:], sender_input.argmax(dim=1), reduction=\"none\"))\n",
    "\n",
    "#    acc=crible_acc*len_mask\n",
    "#    loss=crible_loss*len_mask\n",
    "\n",
    "#    acc2=crible_acc*len_mask2\n",
    "#    loss2=crible_loss*len_mask2\n",
    "#    loss2=torch.cumsum(loss2,dim=1)\n",
    "#    acc2=torch.cumsum(acc2,dim=1)\n",
    "\n",
    "#    loss.add_(loss2)\n",
    "#    acc.add_(acc2)\n",
    "\n",
    "    # Moyenne\n",
    "#    loss.mul_(torch.ones(len_mask.size()).to(\"cuda\")*(1/crible_loss.size(1)))\n",
    "#    acc.mul_(torch.ones(len_mask.size()).to(\"cuda\")*(1/crible_loss.size(1)))\n",
    "\n",
    "#    acc = acc.sum(1)\n",
    "#    loss= loss.sum(1)\n",
    "\n",
    "#    return loss, {'acc': acc}, crible_acc\n",
    "\n",
    "def dump(game, n_features, device, gs_mode, epoch):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "        core.dump_sender_receiver(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    acc_vec=np.zeros(n_features)\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        acc_vec[int(input_symbol)]=acc\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        if epoch%50==0:\n",
    "            print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    #print(f'Mean accuracy wrt uniform distribution is {unif_acc}')\n",
    "    #print(f'Mean accuracy wrt powerlaw distribution is {powerlaw_acc}')\n",
    "    print(json.dumps({'powerlaw': powerlaw_acc, 'unif': unif_acc}))\n",
    "\n",
    "    return acc_vec, messages\n",
    "\n",
    "def dump_impatient(game, n_features, device, gs_mode,epoch):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "        dump_sender_receiver_impatient(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    acc_vec=np.zeros(n_features)\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        acc_vec[int(input_symbol)]=acc\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        if epoch%100==0:\n",
    "            print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    #print(f'Mean accuracy wrt uniform distribution is {unif_acc}')\n",
    "    #print(f'Mean accuracy wrt powerlaw distribution is {powerlaw_acc}')\n",
    "    if epoch%25==0:\n",
    "        print(json.dumps({'powerlaw': powerlaw_acc, 'unif': unif_acc}))\n",
    "\n",
    "    return acc_vec, messages\n",
    "\n",
    "def main(params):\n",
    "    print(torch.cuda.is_available())\n",
    "    opts = get_params(params)\n",
    "    print(opts, flush=True)\n",
    "    device = opts.device\n",
    "\n",
    "    force_eos = opts.force_eos == 1\n",
    "\n",
    "    if opts.probs == 'uniform':\n",
    "        probs = np.ones(opts.n_features)\n",
    "    elif opts.probs == 'powerlaw':\n",
    "        probs = 1 / np.arange(1, opts.n_features+1, dtype=np.float32)\n",
    "    #elif opts.probs == \"creneau\":\n",
    "    #    ones = np.ones(int(opts.n_features/2))\n",
    "    #    tens = 10*np.ones(opts.n_features-int(opts.n_features/2))\n",
    "    #    probs = np.concatenate((tens,ones),axis=0)\n",
    "    #elif opts.probs == \"toy\":\n",
    "    #    fives = 5*np.ones(int(opts.n_features/10))\n",
    "    #    ones = np.ones(opts.n_features-int(opts.n_features/10))\n",
    "    #    probs = np.concatenate((fives,ones),axis=0)\n",
    "    #elif opts.probs == \"escalier\":\n",
    "    #    ones = np.ones(int(opts.n_features/4))\n",
    "    #    tens = 10*np.ones(int(opts.n_features/4))\n",
    "    #    huns = 100*np.ones(int(opts.n_features/4))\n",
    "    #    thous = 1000*np.ones(opts.n_features-3*int(opts.n_features/4))\n",
    "    #    probs = np.concatenate((thous,huns,tens,ones),axis=0)\n",
    "    else:\n",
    "        probs = np.array([float(x) for x in opts.probs.split(',')], dtype=np.float32)\n",
    "\n",
    "    probs /= probs.sum()\n",
    "\n",
    "    print('the probs are: ', probs, flush=True)\n",
    "\n",
    "    train_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                                batches_per_epoch=opts.batches_per_epoch, probs=probs)\n",
    "\n",
    "    # single batches with 1s on the diag\n",
    "    test_loader = UniformLoader(opts.n_features)\n",
    "\n",
    "    if opts.sender_cell == 'transformer':\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_embedding)\n",
    "        sender = core.TransformerSenderReinforce(agent=sender, vocab_size=opts.vocab_size,\n",
    "                                                 embed_dim=opts.sender_embedding, max_len=opts.max_len,\n",
    "                                                 num_layers=opts.sender_num_layers, num_heads=opts.sender_num_heads,\n",
    "                                                 hidden_size=opts.sender_hidden,\n",
    "                                                 force_eos=opts.force_eos,\n",
    "                                                 generate_style=opts.sender_generate_style,\n",
    "                                                 causal=opts.causal_sender)\n",
    "    else:\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_hidden)\n",
    "\n",
    "        sender = core.RnnSenderReinforce(sender,\n",
    "                                   opts.vocab_size, opts.sender_embedding, opts.sender_hidden,\n",
    "                                   cell=opts.sender_cell, max_len=opts.max_len, num_layers=opts.sender_num_layers,\n",
    "                                   force_eos=force_eos)\n",
    "    if opts.receiver_cell == 'transformer':\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_embedding)\n",
    "        receiver = core.TransformerReceiverDeterministic(receiver, opts.vocab_size, opts.max_len,\n",
    "                                                         opts.receiver_embedding, opts.receiver_num_heads, opts.receiver_hidden,\n",
    "                                                         opts.receiver_num_layers, causal=opts.causal_receiver)\n",
    "    else:\n",
    "\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "\n",
    "        if not opts.impatient:\n",
    "          receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "          receiver = core.RnnReceiverDeterministic(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                                 opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                                 num_layers=opts.receiver_num_layers)\n",
    "        else:\n",
    "          receiver = Receiver(n_features=opts.receiver_hidden, n_hidden=opts.vocab_size)\n",
    "          # If impatient 1\n",
    "          receiver = RnnReceiverImpatient(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                            opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                            num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "          # If impatient 2\n",
    "          #receiver = RnnReceiverImpatient2(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "        #                                         opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "        #                                         num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "\n",
    "    if not opts.impatient:\n",
    "        game = core.SenderReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen,reg=opts.reg)\n",
    "    else:\n",
    "        game = SenderImpatientReceiverRnnReinforce(sender, receiver, loss_impatient, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen,reg=opts.reg)\n",
    "\n",
    "    optimizer = core.build_optimizer(game.parameters())\n",
    "\n",
    "    trainer = core.Trainer(game=game, optimizer=optimizer, train_data=train_loader,\n",
    "                           validation_data=test_loader, callbacks=[EarlyStopperAccuracy(opts.early_stopping_thr)])\n",
    "\n",
    "\n",
    "    for epoch in range(int(opts.n_epochs)):\n",
    "\n",
    "        print(\"Epoch: \"+str(epoch))\n",
    "\n",
    "        if epoch%100==0:\n",
    "          trainer.optimizer.defaults[\"lr\"]/=2\n",
    "\n",
    "        trainer.train(n_epochs=1)\n",
    "        if opts.checkpoint_dir:\n",
    "            trainer.save_checkpoint(name=f'{opts.name}_vocab{opts.vocab_size}_rs{opts.random_seed}_lr{opts.lr}_shid{opts.sender_hidden}_rhid{opts.receiver_hidden}_sentr{opts.sender_entropy_coeff}_reg{opts.length_cost}_max_len{opts.max_len}')\n",
    "\n",
    "        if not opts.impatient:\n",
    "            acc_vec,messages=dump(trainer.game, opts.n_features, device, False,epoch)\n",
    "        else:\n",
    "            acc_vec,messages=dump_impatient(trainer.game, opts.n_features, device, False,epoch)\n",
    "\n",
    "        # ADDITION TO SAVE MESSAGES\n",
    "        all_messages=[]\n",
    "        for x in messages:\n",
    "            x = x.cpu().numpy()\n",
    "            all_messages.append(x)\n",
    "        all_messages = np.asarray(all_messages)\n",
    "\n",
    "        if epoch%50==0:\n",
    "            torch.save(sender.state_dict(), opts.dir_save+\"/sender/sender_weights\"+str(epoch)+\".pth\")\n",
    "            torch.save(receiver.state_dict(), opts.dir_save+\"/receiver/receiver_weights\"+str(epoch)+\".pth\")\n",
    "            print(acc_vec)\n",
    "\n",
    "        np.save(opts.dir_save+'/messages/messages_'+str((epoch))+'.npy', all_messages)\n",
    "        np.save(opts.dir_save+'/accuracy/accuracy_'+str((epoch))+'.npy', acc_vec)\n",
    "\n",
    "    core.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    main(['--dir_save=dir_save', '--vocab_size=40', '--max_len=30', '--impatient=False', '--reg=False', '--n_features=100', '--print_message=False', '--random_seed=7',\n",
    "          '--probs=powerlaw', '--n_epoch=200', '--batch_size=512', '--length_cost=0.', '--sender_cell=lstm',  '--receiver_cell=lstm', '--sender_hidden=250',\n",
    "          '--receiver_hidden=600', '--receiver_embedding=100', '--sender_embedding=10', '--batches_per_epoch=100', '--lr=0.001', '--sender_entropy_coeff=2.',\n",
    "          '--sender_num_layers=1', '--receiver_num_layers=1', '--early_stopping_thr=0.99'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59859ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import egg.core as core\n",
    "from egg.core import EarlyStopperAccuracy\n",
    "from egg.zoo.channel.features import OneHotLoader, UniformLoader\n",
    "from egg.zoo.channel.archs import Sender, Receiver\n",
    "from egg.core.util import dump_sender_receiver_test\n",
    "from egg.core.util import dump_impose_message\n",
    "from egg.core.reinforce_wrappers import RnnReceiverImpatient\n",
    "from egg.core.reinforce_wrappers import SenderImpatientReceiverRnnReinforce\n",
    "from egg.core.util import dump_sender_receiver_impatient\n",
    "\n",
    "\n",
    "def get_params(params):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_features', type=int, default=10,\n",
    "                        help='Dimensionality of the \"concept\" space (default: 10)')\n",
    "    parser.add_argument('--batches_per_epoch', type=int, default=1000,\n",
    "                        help='Number of batches per epoch (default: 1000)')\n",
    "    parser.add_argument('--dim_dataset', type=int, default=10240,\n",
    "                        help='Dim of constructing the data (default: 10240)')\n",
    "    parser.add_argument('--force_eos', type=int, default=0,\n",
    "                        help='Force EOS at the end of the messages (default: 0)')\n",
    "\n",
    "    parser.add_argument('--sender_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Receiver (default: 10)')\n",
    "    parser.add_argument('--receiver_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--sender_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--receiver_num_heads', type=int, default=8,\n",
    "                        help='Number of attention heads for Transformer Receiver (default: 8)')\n",
    "    parser.add_argument('--sender_num_heads', type=int, default=8,\n",
    "                        help='Number of self-attention heads for Transformer Sender (default: 8)')\n",
    "    parser.add_argument('--sender_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Receiver (default: 10)')\n",
    "\n",
    "    parser.add_argument('--causal_sender', default=False, action='store_true')\n",
    "    parser.add_argument('--causal_receiver', default=False, action='store_true')\n",
    "\n",
    "    parser.add_argument('--sender_generate_style', type=str, default='in-place', choices=['standard', 'in-place'],\n",
    "                        help='How the next symbol is generated within the TransformerDecoder (default: in-place)')\n",
    "\n",
    "    parser.add_argument('--sender_cell', type=str, default='rnn',\n",
    "                        help='Type of the cell used for Sender {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "    parser.add_argument('--receiver_cell', type=str, default='rnn',\n",
    "                        help='Type of the model used for Receiver {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "\n",
    "    parser.add_argument('--sender_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Sender (default: 1e-1)')\n",
    "    parser.add_argument('--receiver_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Receiver (default: 1e-1)')\n",
    "\n",
    "    parser.add_argument('--probs', type=str, default='uniform',\n",
    "                        help=\"Prior distribution over the concepts (default: uniform)\")\n",
    "    parser.add_argument('--length_cost', type=float, default=0.0,\n",
    "                        help=\"Penalty for the message length, each symbol would before <EOS> would be \"\n",
    "                             \"penalized by this cost (default: 0.0)\")\n",
    "    parser.add_argument('--name', type=str, default='model',\n",
    "                        help=\"Name for your checkpoint (default: model)\")\n",
    "    parser.add_argument('--early_stopping_thr', type=float, default=0.9999,\n",
    "                        help=\"Early stopping threshold on accuracy (default: 0.9999)\")\n",
    "\n",
    "    parser.add_argument('--receiver_weights',type=str ,default=\"receiver_weights.pth\",\n",
    "                        help=\"Weights of the receiver agent\")\n",
    "    parser.add_argument('--sender_weights',type=str ,default=\"sender_weights.pth\",\n",
    "                        help=\"Weights of the sender agent\")\n",
    "    parser.add_argument('--save_dir',type=str ,default=\"analysis/\",\n",
    "                        help=\"Directory to save the results of the analysis\")\n",
    "    parser.add_argument('--impatient', type=bool, default=False,\n",
    "                        help=\"Impatient listener\")\n",
    "    parser.add_argument('--unigram_pen', type=float, default=0.0,\n",
    "                        help=\"Add a penalty for redundancy\")\n",
    "\n",
    "    args = core.init(parser, params)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def loss(sender_input, _message, _receiver_input, receiver_output, _labels):\n",
    "    acc = (receiver_output.argmax(dim=1) == sender_input.argmax(dim=1)).detach().float()\n",
    "    loss = F.cross_entropy(receiver_output, sender_input.argmax(dim=1), reduction=\"none\")\n",
    "    return loss, {'acc': acc}\n",
    "\n",
    "\n",
    "def dump(game, n_features, device, gs_mode):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "            core.dump_sender_receiver(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
    "\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    print(f'Mean accuracy wrt uniform distribution is {unif_acc}')\n",
    "    print(f'Mean accuracy wrt powerlaw distribution is {powerlaw_acc}')\n",
    "    print(json.dumps({'powerlaw': powerlaw_acc, 'unif': unif_acc}))\n",
    "\n",
    "    return acc, messages\n",
    "\n",
    "def dump_impatient(game, n_features, device, gs_mode,save_dir):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "        dump_sender_receiver_impatient(game, dataset, gs=gs_mode, device=device, variable_length=True, test_mode=True,save_dir=save_dir)\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    acc_vec=np.zeros(n_features)\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        acc_vec[int(input_symbol)]=acc\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    #print(f'Mean accuracy wrt uniform distribution is {unif_acc}')\n",
    "    #print(f'Mean accuracy wrt powerlaw distribution is {powerlaw_acc}')\n",
    "    print(json.dumps({'powerlaw': powerlaw_acc, 'unif': unif_acc}))\n",
    "\n",
    "    return acc_vec, messages\n",
    "\n",
    "def position_test(game, n_features, device, gs_mode,pos_min=0,pos_max=1):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "        dump_sender_receiver_test(game,\n",
    "                                       dataset,\n",
    "                                       gs=gs_mode,\n",
    "                                       device=device,\n",
    "                                       variable_length=True,\n",
    "                                       pos_min=pos_min,\n",
    "                                       pos_max=pos_max)\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    print(f'Mean accuracy wrt uniform distribution is {unif_acc}')\n",
    "    print(f'Mean accuracy wrt powerlaw distribution is {powerlaw_acc}')\n",
    "    print(json.dumps({'powerlaw': powerlaw_acc, 'unif': unif_acc}))\n",
    "\n",
    "    return acc, messages\n",
    "\n",
    "def main(params):\n",
    "    opts = get_params(params)\n",
    "    print(opts, flush=True)\n",
    "    device = opts.device\n",
    "\n",
    "    force_eos = opts.force_eos == 1\n",
    "\n",
    "    if opts.probs == 'uniform':\n",
    "        probs = np.ones(opts.n_features)\n",
    "    elif opts.probs == 'powerlaw':\n",
    "        probs = 1 / np.arange(1, opts.n_features+1, dtype=np.float32)\n",
    "    else:\n",
    "        probs = np.array([float(x) for x in opts.probs.split(',')], dtype=np.float32)\n",
    "    probs /= probs.sum()\n",
    "\n",
    "    train_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                                batches_per_epoch=opts.batches_per_epoch, probs=probs)\n",
    "\n",
    "    # single batches with 1s on the diag\n",
    "    test_loader = UniformLoader(opts.n_features)\n",
    "\n",
    "    if opts.sender_cell == 'transformer':\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_embedding)\n",
    "        sender = core.TransformerSenderReinforce(agent=sender, vocab_size=opts.vocab_size,\n",
    "                                                 embed_dim=opts.sender_embedding, max_len=opts.max_len,\n",
    "                                                 num_layers=opts.sender_num_layers, num_heads=opts.sender_num_heads,\n",
    "                                                 hidden_size=opts.sender_hidden,\n",
    "                                                 force_eos=opts.force_eos,\n",
    "                                                 generate_style=opts.sender_generate_style,\n",
    "                                                 causal=opts.causal_sender)\n",
    "    else:\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_hidden)\n",
    "\n",
    "        sender = core.RnnSenderReinforce(sender,\n",
    "                                   opts.vocab_size, opts.sender_embedding, opts.sender_hidden,\n",
    "                                   cell=opts.sender_cell, max_len=opts.max_len, num_layers=opts.sender_num_layers,\n",
    "                                   force_eos=force_eos)\n",
    "    if opts.receiver_cell == 'transformer':\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_embedding)\n",
    "        receiver = core.TransformerReceiverDeterministic(receiver, opts.vocab_size, opts.max_len,\n",
    "                                                         opts.receiver_embedding, opts.receiver_num_heads, opts.receiver_hidden,\n",
    "                                                         opts.receiver_num_layers, causal=opts.causal_receiver)\n",
    "    else:\n",
    "\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "\n",
    "        if not opts.impatient:\n",
    "          receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "          receiver = core.RnnReceiverDeterministic(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                                 opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                                 num_layers=opts.receiver_num_layers)\n",
    "        else:\n",
    "          receiver = Receiver(n_features=opts.receiver_hidden, n_hidden=opts.vocab_size)\n",
    "          # If impatient 1\n",
    "          receiver = RnnReceiverImpatient(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                            opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                            num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "          # If impatient 2\n",
    "          #receiver = RnnReceiverImpatient2(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "        #                                         opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "        #                                         num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "\n",
    "    sender.load_state_dict(torch.load(opts.sender_weights,map_location=torch.device('cpu')))\n",
    "    receiver.load_state_dict(torch.load(opts.receiver_weights,map_location=torch.device('cpu')))\n",
    "\n",
    "    if not opts.impatient:\n",
    "        game = core.SenderReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen)\n",
    "    else:\n",
    "        game = SenderImpatientReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen)\n",
    "\n",
    "    optimizer = core.build_optimizer(game.parameters())\n",
    "\n",
    "    trainer = core.Trainer(game=game, optimizer=optimizer, train_data=train_loader,\n",
    "                           validation_data=test_loader, callbacks=[EarlyStopperAccuracy(opts.early_stopping_thr)])\n",
    "\n",
    "    # Test impose message\n",
    "\n",
    "    if not opts.impatient:\n",
    "        acc_vec,messages=dump(trainer.game, opts.n_features, device, False)\n",
    "    else:\n",
    "        acc_vec,messages=dump_impatient(trainer.game, opts.n_features, device, False,save_dir=opts.save_dir)\n",
    "\n",
    "    all_messages=[]\n",
    "    for x in messages:\n",
    "        x = x.cpu().numpy()\n",
    "        all_messages.append(x)\n",
    "    all_messages = np.asarray(all_messages)\n",
    "\n",
    "    messages=-1*np.ones((opts.n_features,opts.max_len))\n",
    "\n",
    "    for i in range(len(all_messages)):\n",
    "      for j in range(all_messages[i].shape[0]):\n",
    "        messages[i,j]=all_messages[i][j]\n",
    "\n",
    "    np.save(opts.save_dir+\"messages_analysis.npy\",messages)\n",
    "\n",
    "    core.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    main(['--impatient=True', '--save_dir=analysis/', '--receiver_weights=dir_save/receiver/receiver_weights300.pth', '--sender_weights=dir_save/sender/sender_weights300.pth',\n",
    "          '--vocab_size=40',  '--max_len=30', '--n_features=100', '--sender_cell=lstm', '--receiver_cell=lstm', '--sender_hidden=250', '--receiver_hidden=600',\n",
    "          '--receiver_embedding=100', '--sender_embedding=10', '--sender_num_layers=1', '--receiver_num_layers=1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adba79",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import egg.core as core\n",
    "from egg.core import EarlyStopperAccuracy\n",
    "from egg.zoo.channel.features import OneHotLoader, UniformLoader\n",
    "from egg.zoo.channel.archs import Sender, Receiver\n",
    "from egg.core.util import dump_sender_receiver_test\n",
    "from egg.core.util import dump_impose_message\n",
    "from egg.core.util import dump_test_position\n",
    "from egg.core.util import dump_test_position_impatient\n",
    "from egg.core.reinforce_wrappers import RnnReceiverImpatient\n",
    "from egg.core.reinforce_wrappers import SenderImpatientReceiverRnnReinforce\n",
    "from egg.core.util import dump_sender_receiver_impatient\n",
    "\n",
    "\n",
    "def get_params(params):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_features', type=int, default=10,\n",
    "                        help='Dimensionality of the \"concept\" space (default: 10)')\n",
    "    parser.add_argument('--batches_per_epoch', type=int, default=1000,\n",
    "                        help='Number of batches per epoch (default: 1000)')\n",
    "    parser.add_argument('--dim_dataset', type=int, default=10240,\n",
    "                        help='Dim of constructing the data (default: 10240)')\n",
    "    parser.add_argument('--force_eos', type=int, default=0,\n",
    "                        help='Force EOS at the end of the messages (default: 0)')\n",
    "\n",
    "    parser.add_argument('--sender_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Receiver (default: 10)')\n",
    "    parser.add_argument('--receiver_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--sender_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--receiver_num_heads', type=int, default=8,\n",
    "                        help='Number of attention heads for Transformer Receiver (default: 8)')\n",
    "    parser.add_argument('--sender_num_heads', type=int, default=8,\n",
    "                        help='Number of self-attention heads for Transformer Sender (default: 8)')\n",
    "    parser.add_argument('--sender_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Receiver (default: 10)')\n",
    "\n",
    "    parser.add_argument('--causal_sender', default=False, action='store_true')\n",
    "    parser.add_argument('--causal_receiver', default=False, action='store_true')\n",
    "\n",
    "    parser.add_argument('--sender_generate_style', type=str, default='in-place', choices=['standard', 'in-place'],\n",
    "                        help='How the next symbol is generated within the TransformerDecoder (default: in-place)')\n",
    "\n",
    "    parser.add_argument('--sender_cell', type=str, default='rnn',\n",
    "                        help='Type of the cell used for Sender {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "    parser.add_argument('--receiver_cell', type=str, default='rnn',\n",
    "                        help='Type of the model used for Receiver {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "\n",
    "    parser.add_argument('--sender_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Sender (default: 1e-1)')\n",
    "    parser.add_argument('--receiver_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Receiver (default: 1e-1)')\n",
    "\n",
    "    parser.add_argument('--probs', type=str, default='uniform',\n",
    "                        help=\"Prior distribution over the concepts (default: uniform)\")\n",
    "    parser.add_argument('--length_cost', type=float, default=0.0,\n",
    "                        help=\"Penalty for the message length, each symbol would before <EOS> would be \"\n",
    "                             \"penalized by this cost (default: 0.0)\")\n",
    "    parser.add_argument('--name', type=str, default='model',\n",
    "                        help=\"Name for your checkpoint (default: model)\")\n",
    "    parser.add_argument('--early_stopping_thr', type=float, default=0.9999,\n",
    "                        help=\"Early stopping threshold on accuracy (default: 0.9999)\")\n",
    "\n",
    "    parser.add_argument('--receiver_weights',type=str ,default=\"receiver_weights.pth\",\n",
    "                        help=\"Weights of the receiver agent\")\n",
    "    parser.add_argument('--sender_weights',type=str ,default=\"sender_weights.pth\",\n",
    "                        help=\"Weights of the sender agent\")\n",
    "    parser.add_argument('--save_dir',type=str ,default=\"analysis/\",\n",
    "                        help=\"Directory to save the results of the analysis\")\n",
    "    parser.add_argument('--impatient', type=bool, default=False,\n",
    "                        help=\"Impatient listener\")\n",
    "    parser.add_argument('--unigram_pen', type=float, default=0.0,\n",
    "                        help=\"Add a penalty for redundancy\")\n",
    "\n",
    "    args = core.init(parser, params)\n",
    "\n",
    "    return args\n",
    "\n",
    "def dump(game, n_features, device, gs_mode):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "        core.dump_sender_receiver(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        #print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    return acc, messages\n",
    "\n",
    "def loss(sender_input, _message, _receiver_input, receiver_output, _labels):\n",
    "    acc = (receiver_output.argmax(dim=1) == sender_input.argmax(dim=1)).detach().float()\n",
    "    loss = F.cross_entropy(receiver_output, sender_input.argmax(dim=1), reduction=\"none\")\n",
    "    return loss, {'acc': acc}\n",
    "\n",
    "def main(params):\n",
    "    opts = get_params(params)\n",
    "    print(opts, flush=True)\n",
    "    device = opts.device\n",
    "\n",
    "    force_eos = opts.force_eos == 1\n",
    "\n",
    "    if opts.probs == 'uniform':\n",
    "        probs = np.ones(opts.n_features)\n",
    "    elif opts.probs == 'powerlaw':\n",
    "        probs = 1 / np.arange(1, opts.n_features+1, dtype=np.float32)\n",
    "    else:\n",
    "        probs = np.array([float(x) for x in opts.probs.split(',')], dtype=np.float32)\n",
    "    probs /= probs.sum()\n",
    "\n",
    "    train_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                                batches_per_epoch=opts.batches_per_epoch, probs=probs)\n",
    "\n",
    "    # single batches with 1s on the diag\n",
    "    test_loader = UniformLoader(opts.n_features)\n",
    "\n",
    "    if opts.sender_cell == 'transformer':\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_embedding)\n",
    "        sender = core.TransformerSenderReinforce(agent=sender, vocab_size=opts.vocab_size,\n",
    "                                                 embed_dim=opts.sender_embedding, max_len=opts.max_len,\n",
    "                                                 num_layers=opts.sender_num_layers, num_heads=opts.sender_num_heads,\n",
    "                                                 hidden_size=opts.sender_hidden,\n",
    "                                                 force_eos=opts.force_eos,\n",
    "                                                 generate_style=opts.sender_generate_style,\n",
    "                                                 causal=opts.causal_sender)\n",
    "    else:\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_hidden)\n",
    "\n",
    "        sender = core.RnnSenderReinforce(sender,\n",
    "                                   opts.vocab_size, opts.sender_embedding, opts.sender_hidden,\n",
    "                                   cell=opts.sender_cell, max_len=opts.max_len, num_layers=opts.sender_num_layers,\n",
    "                                   force_eos=force_eos)\n",
    "    if opts.receiver_cell == 'transformer':\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_embedding)\n",
    "        receiver = core.TransformerReceiverDeterministic(receiver, opts.vocab_size, opts.max_len,\n",
    "                                                         opts.receiver_embedding, opts.receiver_num_heads, opts.receiver_hidden,\n",
    "                                                         opts.receiver_num_layers, causal=opts.causal_receiver)\n",
    "    else:\n",
    "\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "\n",
    "        if not opts.impatient:\n",
    "          receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "          receiver = core.RnnReceiverDeterministic(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                                 opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                                 num_layers=opts.receiver_num_layers)\n",
    "        else:\n",
    "          receiver = Receiver(n_features=opts.receiver_hidden, n_hidden=opts.vocab_size)\n",
    "          # If impatient 1\n",
    "          receiver = RnnReceiverImpatient(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                            opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                            num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "\n",
    "    sender.load_state_dict(torch.load(opts.sender_weights,map_location=torch.device('cpu')))\n",
    "    receiver.load_state_dict(torch.load(opts.receiver_weights,map_location=torch.device('cpu')))\n",
    "\n",
    "    if not opts.impatient:\n",
    "        game = core.SenderReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen)\n",
    "    else:\n",
    "        game = SenderImpatientReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen)\n",
    "\n",
    "    optimizer = core.build_optimizer(game.parameters())\n",
    "\n",
    "    trainer = core.Trainer(game=game, optimizer=optimizer, train_data=train_loader,\n",
    "                           validation_data=test_loader, callbacks=[EarlyStopperAccuracy(opts.early_stopping_thr)])\n",
    "\n",
    "\n",
    "\n",
    "    # Debut test position\n",
    "\n",
    "    position_sieve=np.zeros((opts.n_features,opts.max_len))\n",
    "\n",
    "    for position in range(opts.max_len):\n",
    "\n",
    "        dataset = [[torch.eye(opts.n_features).to(device), None]]\n",
    "\n",
    "        if opts.impatient:\n",
    "            sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "                dump_test_position_impatient(trainer.game,\n",
    "                                    dataset,\n",
    "                                    position=position,\n",
    "                                    voc_size=opts.vocab_size,\n",
    "                                    gs=False,\n",
    "                                    device=device,\n",
    "                                    variable_length=True)\n",
    "        else:\n",
    "            sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "                dump_test_position(trainer.game,\n",
    "                                    dataset,\n",
    "                                    position=position,\n",
    "                                    voc_size=opts.vocab_size,\n",
    "                                    gs=False,\n",
    "                                    device=device,\n",
    "                                    variable_length=True)\n",
    "\n",
    "        acc_pos=[]\n",
    "\n",
    "        for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "            input_symbol = sender_input.argmax()\n",
    "            output_symbol = receiver_output.argmax()\n",
    "            acc = (input_symbol == output_symbol).float().item()\n",
    "            acc_pos.append(acc)\n",
    "\n",
    "        acc_pos=np.array(acc_pos)\n",
    "\n",
    "        position_sieve[:,position]=acc_pos\n",
    "\n",
    "    # Put -1 for position after message_length\n",
    "    _, messages = dump(trainer.game, opts.n_features, device, False)\n",
    "\n",
    "    # Convert messages to numpy array\n",
    "    messages_np=[]\n",
    "    for x in messages:\n",
    "        x = x.cpu().numpy()\n",
    "        messages_np.append(x)\n",
    "\n",
    "    for i in range(len(messages_np)):\n",
    "        # Message i\n",
    "        message_i=messages_np[i]\n",
    "        id_0=np.where(message_i==0)[0]\n",
    "\n",
    "        if id_0.shape[0]>0:\n",
    "          for j in range(id_0[0]+1,opts.max_len):\n",
    "              position_sieve[i,j]=-1\n",
    "\n",
    "\n",
    "    np.save(\"analysis/position_sieve.npy\",position_sieve)\n",
    "\n",
    "    core.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    main(['--save_dir=analysis/', '--impatient=True', '--sender_weights=dir_save/sender/sender_weights300.pth', '--receiver_weights=dir_save/receiver/receiver_weights300.pth',\n",
    "          '--vocab_size=40', '--n_features=100', '--max_len=30', '--sender_cell=lstm', '--receiver_cell=lstm', '--sender_hidden=250', '--receiver_hidden=600', \n",
    "          '--receiver_embedding=100', '--sender_embedding=10', '--sender_num_layers=1', '--receiver_num_layers=1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load('analysis/position_sieve.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7927a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "message300 = np.load('dir_save/messages/messages_300.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ac911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_message(expe):\n",
    "  \"\"\"\n",
    "  Load messages stored during training procedure/\n",
    "  Return numpy array with all the messages\n",
    "  \"\"\"\n",
    "  np_load_old = np.load\n",
    "  messages = np.load(expe,allow_pickle=True)\n",
    "  np.load = np_load_old\n",
    "  return messages\n",
    "\n",
    "# Choose epochs (between 0 and 500)\n",
    "epochs=[1,150,300]\n",
    "\n",
    "for epoch in epochs:\n",
    "  # Load messages\n",
    "  messages=load_message(\"dir_save/messages/messages_\"+str(epoch)+\".npy\")\n",
    "\n",
    "  # Construct the length distribution\n",
    "  length_distribution=[]\n",
    "  for message in messages:\n",
    "    length_distribution.append(len(message))\n",
    "\n",
    "  # Add epoch to plot\n",
    "  plt.plot(length_distribution,label=\"Epoch \"+str(epoch))\n",
    "\n",
    "# Plot fig\n",
    "plt.title(\"Message length as a function of inputs ranked by frequency\")\n",
    "plt.xlabel(\"Inputs ranked by frequency\")\n",
    "plt.ylabel(\"Message length\")\n",
    "plt.xlim((0,100))\n",
    "plt.ylim((0,32))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy\n",
    "accuracy=[]\n",
    "for i in range(1,300):\n",
    "  accuracy.append(np.mean(np.load(\"dir_save/accuracy/accuracy_\"+str(i)+\".npy\")))\n",
    "\n",
    "# Plot fig\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11,4))\n",
    "ax.plot(accuracy,label=\"LazImpa\",c=\"tab:blue\")\n",
    "ax.set_title(\"Accuracy evolution\")\n",
    "ax.set_xlabel(\"Training episodes\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlim((0,300))\n",
    "ax.set_ylim((0,1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_length_evolution=[]\n",
    "\n",
    "for epoch in range(300):\n",
    "  # Load messages\n",
    "  messages=load_message(\"dir_save/messages/messages_\"+str(epoch)+\".npy\")\n",
    "\n",
    "  # Construct the length distribution\n",
    "  length_distribution=[]\n",
    "  for message in messages:\n",
    "    length_distribution.append(len(message))\n",
    "  \n",
    "  # Get the mean length\n",
    "  mean_length_evolution.append(np.mean(length_distribution))\n",
    "\n",
    "# Plot fig\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11,4))\n",
    "ax.plot(mean_length_evolution,label=\"LazImpa\",c=\"tab:blue\")\n",
    "ax.set_title(\"Mean length evolution\")\n",
    "ax.set_xlabel(\"Training episodes\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlim((0,300))\n",
    "ax.set_ylim((0,31))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
