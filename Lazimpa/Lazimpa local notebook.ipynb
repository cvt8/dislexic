{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54e6a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir -p dir_save/{accuracy,messages,sender,receiver}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb12b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0679cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'egg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01megg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01megg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopperAccuracy\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01megg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mzoo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchannel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotLoader, UniformLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'egg'"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import egg.core as core\n",
    "from egg.core import EarlyStopperAccuracy\n",
    "from egg.zoo.channel.features import OneHotLoader, UniformLoader\n",
    "from egg.zoo.channel.archs import Sender, Receiver\n",
    "from egg.core.reinforce_wrappers import RnnReceiverImpatient\n",
    "from egg.core.reinforce_wrappers import SenderImpatientReceiverRnnReinforce\n",
    "from egg.core.util import dump_sender_receiver_impatient\n",
    "\n",
    "def get_params(params):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_features', type=int, default=10,\n",
    "                        help='Dimensionality of the \"concept\" space (default: 10)')\n",
    "    parser.add_argument('--batches_per_epoch', type=int, default=1000,\n",
    "                        help='Number of batches per epoch (default: 1000)')\n",
    "    parser.add_argument('--dim_dataset', type=int, default=10240,\n",
    "                        help='Dim of constructing the data (default: 10240)')\n",
    "    parser.add_argument('--force_eos', type=int, default=0,\n",
    "                        help='Force EOS at the end of the messages (default: 0)')\n",
    "\n",
    "    parser.add_argument('--sender_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Receiver (default: 10)')\n",
    "    parser.add_argument('--receiver_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--sender_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--receiver_num_heads', type=int, default=8,\n",
    "                        help='Number of attention heads for Transformer Receiver (default: 8)')\n",
    "    parser.add_argument('--sender_num_heads', type=int, default=8,\n",
    "                        help='Number of self-attention heads for Transformer Sender (default: 8)')\n",
    "    parser.add_argument('--sender_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Receiver (default: 10)')\n",
    "\n",
    "    parser.add_argument('--causal_sender', default=False, action='store_true')\n",
    "    parser.add_argument('--causal_receiver', default=False, action='store_true')\n",
    "\n",
    "    parser.add_argument('--sender_generate_style', type=str, default='in-place', choices=['standard', 'in-place'],\n",
    "                        help='How the next symbol is generated within the TransformerDecoder (default: in-place)')\n",
    "\n",
    "    parser.add_argument('--sender_cell', type=str, default='rnn',\n",
    "                        help='Type of the cell used for Sender {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "    parser.add_argument('--receiver_cell', type=str, default='rnn',\n",
    "                        help='Type of the model used for Receiver {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "\n",
    "    parser.add_argument('--sender_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Sender (default: 1e-1)')\n",
    "    parser.add_argument('--receiver_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Receiver (default: 1e-1)')\n",
    "\n",
    "    parser.add_argument('--probs', type=str, default='uniform',\n",
    "                        help=\"Prior distribution over the concepts (default: uniform)\")\n",
    "    parser.add_argument('--length_cost', type=float, default=0.0,\n",
    "                        help=\"Penalty for the message length, each symbol would before <EOS> would be \"\n",
    "                             \"penalized by this cost (default: 0.0)\")\n",
    "    parser.add_argument('--name', type=str, default='model',\n",
    "                        help=\"Name for your checkpoint (default: model)\")\n",
    "    parser.add_argument('--early_stopping_thr', type=float, default=0.9999,\n",
    "                        help=\"Early stopping threshold on accuracy (default: 0.9999)\")\n",
    "\n",
    "    # AJOUT\n",
    "    parser.add_argument('--dir_save', type=str, default=\"expe_1\",\n",
    "                        help=\"Directory in which we will save the information\")\n",
    "    parser.add_argument('--unigram_pen', type=float, default=0.0,\n",
    "                        help=\"Add a penalty for redundancy\")\n",
    "    parser.add_argument('--impatient', type=bool, default=False,\n",
    "                        help=\"Impatient listener\")\n",
    "    parser.add_argument('--print_message', type=bool, default=False,\n",
    "                        help='Print message ?')\n",
    "    parser.add_argument('--reg', type=bool, default=False,\n",
    "                        help='Add regularization ?')\n",
    "\n",
    "    args = core.init(parser, params)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def loss(sender_input, _message, _receiver_input, receiver_output, _labels):\n",
    "    acc = (receiver_output.argmax(dim=1) == sender_input.argmax(dim=1)).detach().float()\n",
    "    loss = F.cross_entropy(receiver_output, sender_input.argmax(dim=1), reduction=\"none\")\n",
    "    return loss, {'acc': acc}\n",
    "\n",
    "def loss_impatient(sender_input, _message, message_length, _receiver_input, receiver_output, _labels):\n",
    "\n",
    "    \"\"\"\n",
    "    Compute the loss function for the Impatient Listener.\n",
    "    It is equal to the average cross entropy of all the intermediate predictions\n",
    "\n",
    "    Params:\n",
    "    - sender_input: ground truth 1-hot vector | size=(batch_size,n_features)\n",
    "    - receiver_output: receiver predictions | size=(batch_size,max_len,n_features)\n",
    "    - message_lengh: message length | size=(batch_size)\n",
    "\n",
    "    Returns:\n",
    "    - loss: |  size= ????\n",
    "    - {acc:acc}: mean accuracy | size=(batch_size)\n",
    "    - crible_acc: accuracy by position | size=(batch_size,max_len)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. len_mask selects only the symbols before EOS-token\n",
    "    to_onehot=torch.eye(_message.size(1)).to(\"cuda\")\n",
    "    to_onehot=torch.cat((to_onehot,torch.zeros((1,_message.size(1))).to(\"cuda\")),0)\n",
    "    len_mask=[]\n",
    "    for i in range(message_length.size(0)):\n",
    "      len_mask.append(to_onehot[message_length[i]])\n",
    "    len_mask=torch.stack(len_mask,dim=0)\n",
    "\n",
    "    len_mask=torch.cumsum(len_mask,dim=1)\n",
    "    len_mask=torch.ones(len_mask.size()).to(\"cuda\").add_(-len_mask)\n",
    "\n",
    "    # 2. coef applies weights on each position. By default it is equal\n",
    "    coef=(1/message_length.to(float)).repeat(_message.size(1),1).transpose(1,0) # useless ?\n",
    "    coef2=coef # useless ?\n",
    "    len_mask.mul_((coef2)) # useless ?\n",
    "    len_mask.mul_((1/len_mask.sum(1)).repeat((_message.size(1),1)).transpose(1,0))\n",
    "\n",
    "    # Test: change positional wieghts\n",
    "    #coef2=coef*torch.arange(_message.size(1),0,-1).repeat(_message.size(0),1).to(\"cuda\")\n",
    "\n",
    "\n",
    "    # 3. crible_acc gathers accuracy for each input/position, crible_loss gathers losses for each input/position\n",
    "    crible_acc=torch.zeros(size=_message.size()).to(\"cuda\")\n",
    "    crible_loss=torch.zeros(size=_message.size()).to(\"cuda\")\n",
    "\n",
    "    for i in range(receiver_output.size(1)):\n",
    "      crible_acc[:,i].add_((receiver_output[:,i,:].argmax(dim=1) == sender_input.argmax(dim=1)).detach().float())\n",
    "      crible_loss[:,i].add_(F.cross_entropy(receiver_output[:,i,:], sender_input.argmax(dim=1), reduction=\"none\"))\n",
    "\n",
    "    # 4. Apply mask to remove the positions after EOS-token\n",
    "    acc=crible_acc*len_mask\n",
    "    loss=crible_loss*len_mask\n",
    "\n",
    "    acc = acc.sum(1)\n",
    "    loss= loss.sum(1)\n",
    "\n",
    "    return loss, {'acc': acc}, crible_acc\n",
    "\n",
    "#def loss_impatient2(sender_input, _message, message_length, _receiver_input, receiver_output, _labels):\n",
    "\n",
    "#    to_onehot=torch.eye(_message.size(1)).to(\"cuda\")\n",
    "#    to_onehot=torch.cat((to_onehot,torch.zeros((1,_message.size(1))).to(\"cuda\")),0)\n",
    "#    len_mask=[]\n",
    "#    len_mask2=[]\n",
    "#    for i in range(message_length.size(0)):\n",
    "#      len_mask.append(to_onehot[message_length[i]])\n",
    "#      len_mask2.append(to_onehot[message_length[i]-1])\n",
    "#    len_mask=torch.stack(len_mask,dim=0)\n",
    "#    len_mask2=torch.stack(len_mask2,dim=0)\n",
    "\n",
    "#    coef=(1/message_length.to(float)).repeat(_message.size(1),1).transpose(1,0)\n",
    "#    coef2=coef*torch.arange(_message.size(1),0,-1).repeat(_message.size(0),1).to(\"cuda\")\n",
    "\n",
    "#    len_mask=torch.cumsum(len_mask,dim=1)\n",
    "#    len_mask=torch.ones(len_mask.size()).to(\"cuda\").add_(-len_mask)\n",
    "\n",
    "#    len_mask.mul_((coef2))\n",
    "#    len_mask.mul_((1/len_mask.sum(1)).repeat((_message.size(1),1)).transpose(1,0))\n",
    "\n",
    "#    crible_acc=torch.zeros(size=_message.size()).to(\"cuda\")\n",
    "#    crible_loss=torch.zeros(size=_message.size()).to(\"cuda\")\n",
    "\n",
    "#    for i in range(receiver_output.size(1)):\n",
    "#      crible_acc[:,i].add_((receiver_output[:,i,:].argmax(dim=1) == sender_input.argmax(dim=1)).detach().float())\n",
    "#      crible_loss[:,i].add_(F.cross_entropy(receiver_output[:,i,:], sender_input.argmax(dim=1), reduction=\"none\"))\n",
    "\n",
    "#    acc=crible_acc*len_mask\n",
    "#    loss=crible_loss*len_mask\n",
    "\n",
    "#    acc2=crible_acc*len_mask2\n",
    "#    loss2=crible_loss*len_mask2\n",
    "#    loss2=torch.cumsum(loss2,dim=1)\n",
    "#    acc2=torch.cumsum(acc2,dim=1)\n",
    "\n",
    "#    loss.add_(loss2)\n",
    "#    acc.add_(acc2)\n",
    "\n",
    "    # Moyenne\n",
    "#    loss.mul_(torch.ones(len_mask.size()).to(\"cuda\")*(1/crible_loss.size(1)))\n",
    "#    acc.mul_(torch.ones(len_mask.size()).to(\"cuda\")*(1/crible_loss.size(1)))\n",
    "\n",
    "#    acc = acc.sum(1)\n",
    "#    loss= loss.sum(1)\n",
    "\n",
    "#    return loss, {'acc': acc}, crible_acc\n",
    "\n",
    "def dump(game, n_features, device, gs_mode, epoch):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "        core.dump_sender_receiver(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    acc_vec=np.zeros(n_features)\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        acc_vec[int(input_symbol)]=acc\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        if epoch%50==0:\n",
    "            print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    #print(f'Mean accuracy wrt uniform distribution is {unif_acc}')\n",
    "    #print(f'Mean accuracy wrt powerlaw distribution is {powerlaw_acc}')\n",
    "    print(json.dumps({'powerlaw': powerlaw_acc, 'unif': unif_acc}))\n",
    "\n",
    "    return acc_vec, messages\n",
    "\n",
    "def dump_impatient(game, n_features, device, gs_mode,epoch):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "        dump_sender_receiver_impatient(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    acc_vec=np.zeros(n_features)\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        acc_vec[int(input_symbol)]=acc\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        if epoch%100==0:\n",
    "            print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    #print(f'Mean accuracy wrt uniform distribution is {unif_acc}')\n",
    "    #print(f'Mean accuracy wrt powerlaw distribution is {powerlaw_acc}')\n",
    "    if epoch%25==0:\n",
    "        print(json.dumps({'powerlaw': powerlaw_acc, 'unif': unif_acc}))\n",
    "\n",
    "    return acc_vec, messages\n",
    "\n",
    "def main(params):\n",
    "    print(torch.cuda.is_available())\n",
    "    opts = get_params(params)\n",
    "    print(opts, flush=True)\n",
    "    device = opts.device\n",
    "\n",
    "    force_eos = opts.force_eos == 1\n",
    "\n",
    "    if opts.probs == 'uniform':\n",
    "        probs = np.ones(opts.n_features)\n",
    "    elif opts.probs == 'powerlaw':\n",
    "        probs = 1 / np.arange(1, opts.n_features+1, dtype=np.float32)\n",
    "    #elif opts.probs == \"creneau\":\n",
    "    #    ones = np.ones(int(opts.n_features/2))\n",
    "    #    tens = 10*np.ones(opts.n_features-int(opts.n_features/2))\n",
    "    #    probs = np.concatenate((tens,ones),axis=0)\n",
    "    #elif opts.probs == \"toy\":\n",
    "    #    fives = 5*np.ones(int(opts.n_features/10))\n",
    "    #    ones = np.ones(opts.n_features-int(opts.n_features/10))\n",
    "    #    probs = np.concatenate((fives,ones),axis=0)\n",
    "    #elif opts.probs == \"escalier\":\n",
    "    #    ones = np.ones(int(opts.n_features/4))\n",
    "    #    tens = 10*np.ones(int(opts.n_features/4))\n",
    "    #    huns = 100*np.ones(int(opts.n_features/4))\n",
    "    #    thous = 1000*np.ones(opts.n_features-3*int(opts.n_features/4))\n",
    "    #    probs = np.concatenate((thous,huns,tens,ones),axis=0)\n",
    "    else:\n",
    "        probs = np.array([float(x) for x in opts.probs.split(',')], dtype=np.float32)\n",
    "\n",
    "    probs /= probs.sum()\n",
    "\n",
    "    print('the probs are: ', probs, flush=True)\n",
    "\n",
    "    train_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                                batches_per_epoch=opts.batches_per_epoch, probs=probs)\n",
    "\n",
    "    # single batches with 1s on the diag\n",
    "    test_loader = UniformLoader(opts.n_features)\n",
    "\n",
    "    if opts.sender_cell == 'transformer':\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_embedding)\n",
    "        sender = core.TransformerSenderReinforce(agent=sender, vocab_size=opts.vocab_size,\n",
    "                                                 embed_dim=opts.sender_embedding, max_len=opts.max_len,\n",
    "                                                 num_layers=opts.sender_num_layers, num_heads=opts.sender_num_heads,\n",
    "                                                 hidden_size=opts.sender_hidden,\n",
    "                                                 force_eos=opts.force_eos,\n",
    "                                                 generate_style=opts.sender_generate_style,\n",
    "                                                 causal=opts.causal_sender)\n",
    "    else:\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_hidden)\n",
    "\n",
    "        sender = core.RnnSenderReinforce(sender,\n",
    "                                   opts.vocab_size, opts.sender_embedding, opts.sender_hidden,\n",
    "                                   cell=opts.sender_cell, max_len=opts.max_len, num_layers=opts.sender_num_layers,\n",
    "                                   force_eos=force_eos)\n",
    "    if opts.receiver_cell == 'transformer':\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_embedding)\n",
    "        receiver = core.TransformerReceiverDeterministic(receiver, opts.vocab_size, opts.max_len,\n",
    "                                                         opts.receiver_embedding, opts.receiver_num_heads, opts.receiver_hidden,\n",
    "                                                         opts.receiver_num_layers, causal=opts.causal_receiver)\n",
    "    else:\n",
    "\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "\n",
    "        if not opts.impatient:\n",
    "          receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "          receiver = core.RnnReceiverDeterministic(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                                 opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                                 num_layers=opts.receiver_num_layers)\n",
    "        else:\n",
    "          receiver = Receiver(n_features=opts.receiver_hidden, n_hidden=opts.vocab_size)\n",
    "          # If impatient 1\n",
    "          receiver = RnnReceiverImpatient(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                            opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                            num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "          # If impatient 2\n",
    "          #receiver = RnnReceiverImpatient2(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "        #                                         opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "        #                                         num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "\n",
    "    if not opts.impatient:\n",
    "        game = core.SenderReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen,reg=opts.reg)\n",
    "    else:\n",
    "        game = SenderImpatientReceiverRnnReinforce(sender, receiver, loss_impatient, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen,reg=opts.reg)\n",
    "\n",
    "    optimizer = core.build_optimizer(game.parameters())\n",
    "\n",
    "    trainer = core.Trainer(game=game, optimizer=optimizer, train_data=train_loader,\n",
    "                           validation_data=test_loader, callbacks=[EarlyStopperAccuracy(opts.early_stopping_thr)])\n",
    "\n",
    "\n",
    "    for epoch in range(int(opts.n_epochs)):\n",
    "\n",
    "        print(\"Epoch: \"+str(epoch))\n",
    "\n",
    "        if epoch%100==0:\n",
    "          trainer.optimizer.defaults[\"lr\"]/=2\n",
    "\n",
    "        trainer.train(n_epochs=1)\n",
    "        if opts.checkpoint_dir:\n",
    "            trainer.save_checkpoint(name=f'{opts.name}_vocab{opts.vocab_size}_rs{opts.random_seed}_lr{opts.lr}_shid{opts.sender_hidden}_rhid{opts.receiver_hidden}_sentr{opts.sender_entropy_coeff}_reg{opts.length_cost}_max_len{opts.max_len}')\n",
    "\n",
    "        if not opts.impatient:\n",
    "            acc_vec,messages=dump(trainer.game, opts.n_features, device, False,epoch)\n",
    "        else:\n",
    "            acc_vec,messages=dump_impatient(trainer.game, opts.n_features, device, False,epoch)\n",
    "\n",
    "        # ADDITION TO SAVE MESSAGES\n",
    "        all_messages=[]\n",
    "        for x in messages:\n",
    "            x = x.cpu().numpy()\n",
    "            all_messages.append(x)\n",
    "        all_messages = np.asarray(all_messages)\n",
    "\n",
    "        if epoch%50==0:\n",
    "            torch.save(sender.state_dict(), opts.dir_save+\"/sender/sender_weights\"+str(epoch)+\".pth\")\n",
    "            torch.save(receiver.state_dict(), opts.dir_save+\"/receiver/receiver_weights\"+str(epoch)+\".pth\")\n",
    "            print(acc_vec)\n",
    "\n",
    "        np.save(opts.dir_save+'/messages/messages_'+str((epoch))+'.npy', all_messages)\n",
    "        np.save(opts.dir_save+'/accuracy/accuracy_'+str((epoch))+'.npy', acc_vec)\n",
    "\n",
    "    core.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    main(['--dir_save=dir_save', '--vocab_size=40', '--max_len=30', '--impatient=False', '--reg=False', '--n_features=100', '--print_message=False', '--random_seed=7',\n",
    "          '--probs=powerlaw', '--n_epoch=200', '--batch_size=512', '--length_cost=0.', '--sender_cell=lstm',  '--receiver_cell=lstm', '--sender_hidden=250',\n",
    "          '--receiver_hidden=600', '--receiver_embedding=100', '--sender_embedding=10', '--batches_per_epoch=100', '--lr=0.001', '--sender_entropy_coeff=2.',\n",
    "          '--sender_num_layers=1', '--receiver_num_layers=1', '--early_stopping_thr=0.99'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59859ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import egg.core as core\n",
    "from egg.core import EarlyStopperAccuracy\n",
    "from egg.zoo.channel.features import OneHotLoader, UniformLoader\n",
    "from egg.zoo.channel.archs import Sender, Receiver\n",
    "from egg.core.util import dump_sender_receiver_test\n",
    "from egg.core.util import dump_impose_message\n",
    "from egg.core.reinforce_wrappers import RnnReceiverImpatient\n",
    "from egg.core.reinforce_wrappers import SenderImpatientReceiverRnnReinforce\n",
    "from egg.core.util import dump_sender_receiver_impatient\n",
    "\n",
    "\n",
    "def get_params(params):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_features', type=int, default=10,\n",
    "                        help='Dimensionality of the \"concept\" space (default: 10)')\n",
    "    parser.add_argument('--batches_per_epoch', type=int, default=1000,\n",
    "                        help='Number of batches per epoch (default: 1000)')\n",
    "    parser.add_argument('--dim_dataset', type=int, default=10240,\n",
    "                        help='Dim of constructing the data (default: 10240)')\n",
    "    parser.add_argument('--force_eos', type=int, default=0,\n",
    "                        help='Force EOS at the end of the messages (default: 0)')\n",
    "\n",
    "    parser.add_argument('--sender_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Receiver (default: 10)')\n",
    "    parser.add_argument('--receiver_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--sender_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--receiver_num_heads', type=int, default=8,\n",
    "                        help='Number of attention heads for Transformer Receiver (default: 8)')\n",
    "    parser.add_argument('--sender_num_heads', type=int, default=8,\n",
    "                        help='Number of self-attention heads for Transformer Sender (default: 8)')\n",
    "    parser.add_argument('--sender_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Receiver (default: 10)')\n",
    "\n",
    "    parser.add_argument('--causal_sender', default=False, action='store_true')\n",
    "    parser.add_argument('--causal_receiver', default=False, action='store_true')\n",
    "\n",
    "    parser.add_argument('--sender_generate_style', type=str, default='in-place', choices=['standard', 'in-place'],\n",
    "                        help='How the next symbol is generated within the TransformerDecoder (default: in-place)')\n",
    "\n",
    "    parser.add_argument('--sender_cell', type=str, default='rnn',\n",
    "                        help='Type of the cell used for Sender {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "    parser.add_argument('--receiver_cell', type=str, default='rnn',\n",
    "                        help='Type of the model used for Receiver {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "\n",
    "    parser.add_argument('--sender_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Sender (default: 1e-1)')\n",
    "    parser.add_argument('--receiver_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Receiver (default: 1e-1)')\n",
    "\n",
    "    parser.add_argument('--probs', type=str, default='uniform',\n",
    "                        help=\"Prior distribution over the concepts (default: uniform)\")\n",
    "    parser.add_argument('--length_cost', type=float, default=0.0,\n",
    "                        help=\"Penalty for the message length, each symbol would before <EOS> would be \"\n",
    "                             \"penalized by this cost (default: 0.0)\")\n",
    "    parser.add_argument('--name', type=str, default='model',\n",
    "                        help=\"Name for your checkpoint (default: model)\")\n",
    "    parser.add_argument('--early_stopping_thr', type=float, default=0.9999,\n",
    "                        help=\"Early stopping threshold on accuracy (default: 0.9999)\")\n",
    "\n",
    "    parser.add_argument('--receiver_weights',type=str ,default=\"receiver_weights.pth\",\n",
    "                        help=\"Weights of the receiver agent\")\n",
    "    parser.add_argument('--sender_weights',type=str ,default=\"sender_weights.pth\",\n",
    "                        help=\"Weights of the sender agent\")\n",
    "    parser.add_argument('--save_dir',type=str ,default=\"analysis/\",\n",
    "                        help=\"Directory to save the results of the analysis\")\n",
    "    parser.add_argument('--impatient', type=bool, default=False,\n",
    "                        help=\"Impatient listener\")\n",
    "    parser.add_argument('--unigram_pen', type=float, default=0.0,\n",
    "                        help=\"Add a penalty for redundancy\")\n",
    "\n",
    "    args = core.init(parser, params)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def loss(sender_input, _message, _receiver_input, receiver_output, _labels):\n",
    "    acc = (receiver_output.argmax(dim=1) == sender_input.argmax(dim=1)).detach().float()\n",
    "    loss = F.cross_entropy(receiver_output, sender_input.argmax(dim=1), reduction=\"none\")\n",
    "    return loss, {'acc': acc}\n",
    "\n",
    "\n",
    "def dump(game, n_features, device, gs_mode):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "            core.dump_sender_receiver(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
    "\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    print(f'Mean accuracy wrt uniform distribution is {unif_acc}')\n",
    "    print(f'Mean accuracy wrt powerlaw distribution is {powerlaw_acc}')\n",
    "    print(json.dumps({'powerlaw': powerlaw_acc, 'unif': unif_acc}))\n",
    "\n",
    "    return acc, messages\n",
    "\n",
    "def dump_impatient(game, n_features, device, gs_mode,save_dir):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "        dump_sender_receiver_impatient(game, dataset, gs=gs_mode, device=device, variable_length=True, test_mode=True,save_dir=save_dir)\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    acc_vec=np.zeros(n_features)\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        acc_vec[int(input_symbol)]=acc\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    #print(f'Mean accuracy wrt uniform distribution is {unif_acc}')\n",
    "    #print(f'Mean accuracy wrt powerlaw distribution is {powerlaw_acc}')\n",
    "    print(json.dumps({'powerlaw': powerlaw_acc, 'unif': unif_acc}))\n",
    "\n",
    "    return acc_vec, messages\n",
    "\n",
    "def position_test(game, n_features, device, gs_mode,pos_min=0,pos_max=1):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "        dump_sender_receiver_test(game,\n",
    "                                       dataset,\n",
    "                                       gs=gs_mode,\n",
    "                                       device=device,\n",
    "                                       variable_length=True,\n",
    "                                       pos_min=pos_min,\n",
    "                                       pos_max=pos_max)\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    print(f'Mean accuracy wrt uniform distribution is {unif_acc}')\n",
    "    print(f'Mean accuracy wrt powerlaw distribution is {powerlaw_acc}')\n",
    "    print(json.dumps({'powerlaw': powerlaw_acc, 'unif': unif_acc}))\n",
    "\n",
    "    return acc, messages\n",
    "\n",
    "def main(params):\n",
    "    opts = get_params(params)\n",
    "    print(opts, flush=True)\n",
    "    device = opts.device\n",
    "\n",
    "    force_eos = opts.force_eos == 1\n",
    "\n",
    "    if opts.probs == 'uniform':\n",
    "        probs = np.ones(opts.n_features)\n",
    "    elif opts.probs == 'powerlaw':\n",
    "        probs = 1 / np.arange(1, opts.n_features+1, dtype=np.float32)\n",
    "    else:\n",
    "        probs = np.array([float(x) for x in opts.probs.split(',')], dtype=np.float32)\n",
    "    probs /= probs.sum()\n",
    "\n",
    "    train_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                                batches_per_epoch=opts.batches_per_epoch, probs=probs)\n",
    "\n",
    "    # single batches with 1s on the diag\n",
    "    test_loader = UniformLoader(opts.n_features)\n",
    "\n",
    "    if opts.sender_cell == 'transformer':\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_embedding)\n",
    "        sender = core.TransformerSenderReinforce(agent=sender, vocab_size=opts.vocab_size,\n",
    "                                                 embed_dim=opts.sender_embedding, max_len=opts.max_len,\n",
    "                                                 num_layers=opts.sender_num_layers, num_heads=opts.sender_num_heads,\n",
    "                                                 hidden_size=opts.sender_hidden,\n",
    "                                                 force_eos=opts.force_eos,\n",
    "                                                 generate_style=opts.sender_generate_style,\n",
    "                                                 causal=opts.causal_sender)\n",
    "    else:\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_hidden)\n",
    "\n",
    "        sender = core.RnnSenderReinforce(sender,\n",
    "                                   opts.vocab_size, opts.sender_embedding, opts.sender_hidden,\n",
    "                                   cell=opts.sender_cell, max_len=opts.max_len, num_layers=opts.sender_num_layers,\n",
    "                                   force_eos=force_eos)\n",
    "    if opts.receiver_cell == 'transformer':\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_embedding)\n",
    "        receiver = core.TransformerReceiverDeterministic(receiver, opts.vocab_size, opts.max_len,\n",
    "                                                         opts.receiver_embedding, opts.receiver_num_heads, opts.receiver_hidden,\n",
    "                                                         opts.receiver_num_layers, causal=opts.causal_receiver)\n",
    "    else:\n",
    "\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "\n",
    "        if not opts.impatient:\n",
    "          receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "          receiver = core.RnnReceiverDeterministic(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                                 opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                                 num_layers=opts.receiver_num_layers)\n",
    "        else:\n",
    "          receiver = Receiver(n_features=opts.receiver_hidden, n_hidden=opts.vocab_size)\n",
    "          # If impatient 1\n",
    "          receiver = RnnReceiverImpatient(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                            opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                            num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "          # If impatient 2\n",
    "          #receiver = RnnReceiverImpatient2(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "        #                                         opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "        #                                         num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "\n",
    "    sender.load_state_dict(torch.load(opts.sender_weights,map_location=torch.device('cpu')))\n",
    "    receiver.load_state_dict(torch.load(opts.receiver_weights,map_location=torch.device('cpu')))\n",
    "\n",
    "    if not opts.impatient:\n",
    "        game = core.SenderReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen)\n",
    "    else:\n",
    "        game = SenderImpatientReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen)\n",
    "\n",
    "    optimizer = core.build_optimizer(game.parameters())\n",
    "\n",
    "    trainer = core.Trainer(game=game, optimizer=optimizer, train_data=train_loader,\n",
    "                           validation_data=test_loader, callbacks=[EarlyStopperAccuracy(opts.early_stopping_thr)])\n",
    "\n",
    "    # Test impose message\n",
    "\n",
    "    if not opts.impatient:\n",
    "        acc_vec,messages=dump(trainer.game, opts.n_features, device, False)\n",
    "    else:\n",
    "        acc_vec,messages=dump_impatient(trainer.game, opts.n_features, device, False,save_dir=opts.save_dir)\n",
    "\n",
    "    all_messages=[]\n",
    "    for x in messages:\n",
    "        x = x.cpu().numpy()\n",
    "        all_messages.append(x)\n",
    "    all_messages = np.asarray(all_messages)\n",
    "\n",
    "    messages=-1*np.ones((opts.n_features,opts.max_len))\n",
    "\n",
    "    for i in range(len(all_messages)):\n",
    "      for j in range(all_messages[i].shape[0]):\n",
    "        messages[i,j]=all_messages[i][j]\n",
    "\n",
    "    np.save(opts.save_dir+\"messages_analysis.npy\",messages)\n",
    "\n",
    "    core.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    main(['--impatient=True', '--save_dir=analysis/', '--receiver_weights=dir_save/receiver/receiver_weights300.pth', '--sender_weights=dir_save/sender/sender_weights300.pth',\n",
    "          '--vocab_size=40',  '--max_len=30', '--n_features=100', '--sender_cell=lstm', '--receiver_cell=lstm', '--sender_hidden=250', '--receiver_hidden=600',\n",
    "          '--receiver_embedding=100', '--sender_embedding=10', '--sender_num_layers=1', '--receiver_num_layers=1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adba79",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import egg.core as core\n",
    "from egg.core import EarlyStopperAccuracy\n",
    "from egg.zoo.channel.features import OneHotLoader, UniformLoader\n",
    "from egg.zoo.channel.archs import Sender, Receiver\n",
    "from egg.core.util import dump_sender_receiver_test\n",
    "from egg.core.util import dump_impose_message\n",
    "from egg.core.util import dump_test_position\n",
    "from egg.core.util import dump_test_position_impatient\n",
    "from egg.core.reinforce_wrappers import RnnReceiverImpatient\n",
    "from egg.core.reinforce_wrappers import SenderImpatientReceiverRnnReinforce\n",
    "from egg.core.util import dump_sender_receiver_impatient\n",
    "\n",
    "\n",
    "def get_params(params):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_features', type=int, default=10,\n",
    "                        help='Dimensionality of the \"concept\" space (default: 10)')\n",
    "    parser.add_argument('--batches_per_epoch', type=int, default=1000,\n",
    "                        help='Number of batches per epoch (default: 1000)')\n",
    "    parser.add_argument('--dim_dataset', type=int, default=10240,\n",
    "                        help='Dim of constructing the data (default: 10240)')\n",
    "    parser.add_argument('--force_eos', type=int, default=0,\n",
    "                        help='Force EOS at the end of the messages (default: 0)')\n",
    "\n",
    "    parser.add_argument('--sender_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_hidden', type=int, default=10,\n",
    "                        help='Size of the hidden layer of Receiver (default: 10)')\n",
    "    parser.add_argument('--receiver_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--sender_num_layers', type=int, default=1,\n",
    "                        help='Number hidden layers of receiver. Only in reinforce (default: 1)')\n",
    "    parser.add_argument('--receiver_num_heads', type=int, default=8,\n",
    "                        help='Number of attention heads for Transformer Receiver (default: 8)')\n",
    "    parser.add_argument('--sender_num_heads', type=int, default=8,\n",
    "                        help='Number of self-attention heads for Transformer Sender (default: 8)')\n",
    "    parser.add_argument('--sender_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Sender (default: 10)')\n",
    "    parser.add_argument('--receiver_embedding', type=int, default=10,\n",
    "                        help='Dimensionality of the embedding hidden layer for Receiver (default: 10)')\n",
    "\n",
    "    parser.add_argument('--causal_sender', default=False, action='store_true')\n",
    "    parser.add_argument('--causal_receiver', default=False, action='store_true')\n",
    "\n",
    "    parser.add_argument('--sender_generate_style', type=str, default='in-place', choices=['standard', 'in-place'],\n",
    "                        help='How the next symbol is generated within the TransformerDecoder (default: in-place)')\n",
    "\n",
    "    parser.add_argument('--sender_cell', type=str, default='rnn',\n",
    "                        help='Type of the cell used for Sender {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "    parser.add_argument('--receiver_cell', type=str, default='rnn',\n",
    "                        help='Type of the model used for Receiver {rnn, gru, lstm, transformer} (default: rnn)')\n",
    "\n",
    "    parser.add_argument('--sender_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Sender (default: 1e-1)')\n",
    "    parser.add_argument('--receiver_entropy_coeff', type=float, default=1e-1,\n",
    "                        help='The entropy regularisation coefficient for Receiver (default: 1e-1)')\n",
    "\n",
    "    parser.add_argument('--probs', type=str, default='uniform',\n",
    "                        help=\"Prior distribution over the concepts (default: uniform)\")\n",
    "    parser.add_argument('--length_cost', type=float, default=0.0,\n",
    "                        help=\"Penalty for the message length, each symbol would before <EOS> would be \"\n",
    "                             \"penalized by this cost (default: 0.0)\")\n",
    "    parser.add_argument('--name', type=str, default='model',\n",
    "                        help=\"Name for your checkpoint (default: model)\")\n",
    "    parser.add_argument('--early_stopping_thr', type=float, default=0.9999,\n",
    "                        help=\"Early stopping threshold on accuracy (default: 0.9999)\")\n",
    "\n",
    "    parser.add_argument('--receiver_weights',type=str ,default=\"receiver_weights.pth\",\n",
    "                        help=\"Weights of the receiver agent\")\n",
    "    parser.add_argument('--sender_weights',type=str ,default=\"sender_weights.pth\",\n",
    "                        help=\"Weights of the sender agent\")\n",
    "    parser.add_argument('--save_dir',type=str ,default=\"analysis/\",\n",
    "                        help=\"Directory to save the results of the analysis\")\n",
    "    parser.add_argument('--impatient', type=bool, default=False,\n",
    "                        help=\"Impatient listener\")\n",
    "    parser.add_argument('--unigram_pen', type=float, default=0.0,\n",
    "                        help=\"Add a penalty for redundancy\")\n",
    "\n",
    "    args = core.init(parser, params)\n",
    "\n",
    "    return args\n",
    "\n",
    "def dump(game, n_features, device, gs_mode):\n",
    "    # tiny \"dataset\"\n",
    "    dataset = [[torch.eye(n_features).to(device), None]]\n",
    "\n",
    "    sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "        core.dump_sender_receiver(game, dataset, gs=gs_mode, device=device, variable_length=True)\n",
    "\n",
    "    unif_acc = 0.\n",
    "    powerlaw_acc = 0.\n",
    "    powerlaw_probs = 1 / np.arange(1, n_features+1, dtype=np.float32)\n",
    "    powerlaw_probs /= powerlaw_probs.sum()\n",
    "\n",
    "    for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "        input_symbol = sender_input.argmax()\n",
    "        output_symbol = receiver_output.argmax()\n",
    "        acc = (input_symbol == output_symbol).float().item()\n",
    "\n",
    "        unif_acc += acc\n",
    "        powerlaw_acc += powerlaw_probs[input_symbol] * acc\n",
    "        #print(f'input: {input_symbol.item()} -> message: {\",\".join([str(x.item()) for x in message])} -> output: {output_symbol.item()}', flush=True)\n",
    "\n",
    "    unif_acc /= n_features\n",
    "\n",
    "    return acc, messages\n",
    "\n",
    "def loss(sender_input, _message, _receiver_input, receiver_output, _labels):\n",
    "    acc = (receiver_output.argmax(dim=1) == sender_input.argmax(dim=1)).detach().float()\n",
    "    loss = F.cross_entropy(receiver_output, sender_input.argmax(dim=1), reduction=\"none\")\n",
    "    return loss, {'acc': acc}\n",
    "\n",
    "def main(params):\n",
    "    opts = get_params(params)\n",
    "    print(opts, flush=True)\n",
    "    device = opts.device\n",
    "\n",
    "    force_eos = opts.force_eos == 1\n",
    "\n",
    "    if opts.probs == 'uniform':\n",
    "        probs = np.ones(opts.n_features)\n",
    "    elif opts.probs == 'powerlaw':\n",
    "        probs = 1 / np.arange(1, opts.n_features+1, dtype=np.float32)\n",
    "    else:\n",
    "        probs = np.array([float(x) for x in opts.probs.split(',')], dtype=np.float32)\n",
    "    probs /= probs.sum()\n",
    "\n",
    "    train_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                                batches_per_epoch=opts.batches_per_epoch, probs=probs)\n",
    "\n",
    "    # single batches with 1s on the diag\n",
    "    test_loader = UniformLoader(opts.n_features)\n",
    "\n",
    "    if opts.sender_cell == 'transformer':\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_embedding)\n",
    "        sender = core.TransformerSenderReinforce(agent=sender, vocab_size=opts.vocab_size,\n",
    "                                                 embed_dim=opts.sender_embedding, max_len=opts.max_len,\n",
    "                                                 num_layers=opts.sender_num_layers, num_heads=opts.sender_num_heads,\n",
    "                                                 hidden_size=opts.sender_hidden,\n",
    "                                                 force_eos=opts.force_eos,\n",
    "                                                 generate_style=opts.sender_generate_style,\n",
    "                                                 causal=opts.causal_sender)\n",
    "    else:\n",
    "        sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_hidden)\n",
    "\n",
    "        sender = core.RnnSenderReinforce(sender,\n",
    "                                   opts.vocab_size, opts.sender_embedding, opts.sender_hidden,\n",
    "                                   cell=opts.sender_cell, max_len=opts.max_len, num_layers=opts.sender_num_layers,\n",
    "                                   force_eos=force_eos)\n",
    "    if opts.receiver_cell == 'transformer':\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_embedding)\n",
    "        receiver = core.TransformerReceiverDeterministic(receiver, opts.vocab_size, opts.max_len,\n",
    "                                                         opts.receiver_embedding, opts.receiver_num_heads, opts.receiver_hidden,\n",
    "                                                         opts.receiver_num_layers, causal=opts.causal_receiver)\n",
    "    else:\n",
    "\n",
    "        receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "\n",
    "        if not opts.impatient:\n",
    "          receiver = Receiver(n_features=opts.n_features, n_hidden=opts.receiver_hidden)\n",
    "          receiver = core.RnnReceiverDeterministic(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                                 opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                                 num_layers=opts.receiver_num_layers)\n",
    "        else:\n",
    "          receiver = Receiver(n_features=opts.receiver_hidden, n_hidden=opts.vocab_size)\n",
    "          # If impatient 1\n",
    "          receiver = RnnReceiverImpatient(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                            opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                            num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "\n",
    "    sender.load_state_dict(torch.load(opts.sender_weights,map_location=torch.device('cpu')))\n",
    "    receiver.load_state_dict(torch.load(opts.receiver_weights,map_location=torch.device('cpu')))\n",
    "\n",
    "    if not opts.impatient:\n",
    "        game = core.SenderReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen)\n",
    "    else:\n",
    "        game = SenderImpatientReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen)\n",
    "\n",
    "    optimizer = core.build_optimizer(game.parameters())\n",
    "\n",
    "    trainer = core.Trainer(game=game, optimizer=optimizer, train_data=train_loader,\n",
    "                           validation_data=test_loader, callbacks=[EarlyStopperAccuracy(opts.early_stopping_thr)])\n",
    "\n",
    "\n",
    "\n",
    "    # Debut test position\n",
    "\n",
    "    position_sieve=np.zeros((opts.n_features,opts.max_len))\n",
    "\n",
    "    for position in range(opts.max_len):\n",
    "\n",
    "        dataset = [[torch.eye(opts.n_features).to(device), None]]\n",
    "\n",
    "        if opts.impatient:\n",
    "            sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "                dump_test_position_impatient(trainer.game,\n",
    "                                    dataset,\n",
    "                                    position=position,\n",
    "                                    voc_size=opts.vocab_size,\n",
    "                                    gs=False,\n",
    "                                    device=device,\n",
    "                                    variable_length=True)\n",
    "        else:\n",
    "            sender_inputs, messages, receiver_inputs, receiver_outputs, _ = \\\n",
    "                dump_test_position(trainer.game,\n",
    "                                    dataset,\n",
    "                                    position=position,\n",
    "                                    voc_size=opts.vocab_size,\n",
    "                                    gs=False,\n",
    "                                    device=device,\n",
    "                                    variable_length=True)\n",
    "\n",
    "        acc_pos=[]\n",
    "\n",
    "        for sender_input, message, receiver_output in zip(sender_inputs, messages, receiver_outputs):\n",
    "            input_symbol = sender_input.argmax()\n",
    "            output_symbol = receiver_output.argmax()\n",
    "            acc = (input_symbol == output_symbol).float().item()\n",
    "            acc_pos.append(acc)\n",
    "\n",
    "        acc_pos=np.array(acc_pos)\n",
    "\n",
    "        position_sieve[:,position]=acc_pos\n",
    "\n",
    "    # Put -1 for position after message_length\n",
    "    _, messages = dump(trainer.game, opts.n_features, device, False)\n",
    "\n",
    "    # Convert messages to numpy array\n",
    "    messages_np=[]\n",
    "    for x in messages:\n",
    "        x = x.cpu().numpy()\n",
    "        messages_np.append(x)\n",
    "\n",
    "    for i in range(len(messages_np)):\n",
    "        # Message i\n",
    "        message_i=messages_np[i]\n",
    "        id_0=np.where(message_i==0)[0]\n",
    "\n",
    "        if id_0.shape[0]>0:\n",
    "          for j in range(id_0[0]+1,opts.max_len):\n",
    "              position_sieve[i,j]=-1\n",
    "\n",
    "\n",
    "    np.save(\"analysis/position_sieve.npy\",position_sieve)\n",
    "\n",
    "    core.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    main(['--save_dir=analysis/', '--impatient=True', '--sender_weights=dir_save/sender/sender_weights300.pth', '--receiver_weights=dir_save/receiver/receiver_weights300.pth',\n",
    "          '--vocab_size=40', '--n_features=100', '--max_len=30', '--sender_cell=lstm', '--receiver_cell=lstm', '--sender_hidden=250', '--receiver_hidden=600', \n",
    "          '--receiver_embedding=100', '--sender_embedding=10', '--sender_num_layers=1', '--receiver_num_layers=1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load('analysis/position_sieve.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7927a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "message300 = np.load('dir_save/messages/messages_300.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ac911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_message(expe):\n",
    "  \"\"\"\n",
    "  Load messages stored during training procedure/\n",
    "  Return numpy array with all the messages\n",
    "  \"\"\"\n",
    "  np_load_old = np.load\n",
    "  messages = np.load(expe,allow_pickle=True)\n",
    "  np.load = np_load_old\n",
    "  return messages\n",
    "\n",
    "# Choose epochs (between 0 and 500)\n",
    "epochs=[1,150,300]\n",
    "\n",
    "for epoch in epochs:\n",
    "  # Load messages\n",
    "  messages=load_message(\"dir_save/messages/messages_\"+str(epoch)+\".npy\")\n",
    "\n",
    "  # Construct the length distribution\n",
    "  length_distribution=[]\n",
    "  for message in messages:\n",
    "    length_distribution.append(len(message))\n",
    "\n",
    "  # Add epoch to plot\n",
    "  plt.plot(length_distribution,label=\"Epoch \"+str(epoch))\n",
    "\n",
    "# Plot fig\n",
    "plt.title(\"Message length as a function of inputs ranked by frequency\")\n",
    "plt.xlabel(\"Inputs ranked by frequency\")\n",
    "plt.ylabel(\"Message length\")\n",
    "plt.xlim((0,100))\n",
    "plt.ylim((0,32))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy\n",
    "accuracy=[]\n",
    "for i in range(1,300):\n",
    "  accuracy.append(np.mean(np.load(\"dir_save/accuracy/accuracy_\"+str(i)+\".npy\")))\n",
    "\n",
    "# Plot fig\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11,4))\n",
    "ax.plot(accuracy,label=\"LazImpa\",c=\"tab:blue\")\n",
    "ax.set_title(\"Accuracy evolution\")\n",
    "ax.set_xlabel(\"Training episodes\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlim((0,300))\n",
    "ax.set_ylim((0,1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_length_evolution=[]\n",
    "\n",
    "for epoch in range(300):\n",
    "  # Load messages\n",
    "  messages=load_message(\"dir_save/messages/messages_\"+str(epoch)+\".npy\")\n",
    "\n",
    "  # Construct the length distribution\n",
    "  length_distribution=[]\n",
    "  for message in messages:\n",
    "    length_distribution.append(len(message))\n",
    "  \n",
    "  # Get the mean length\n",
    "  mean_length_evolution.append(np.mean(length_distribution))\n",
    "\n",
    "# Plot fig\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11,4))\n",
    "ax.plot(mean_length_evolution,label=\"LazImpa\",c=\"tab:blue\")\n",
    "ax.set_title(\"Mean length evolution\")\n",
    "ax.set_xlabel(\"Training episodes\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlim((0,300))\n",
    "ax.set_ylim((0,31))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
